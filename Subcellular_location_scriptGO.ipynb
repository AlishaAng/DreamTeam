{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Subcellular Location using QuickGO REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #loading csv package\n",
    "import pandas as pd #loading pandas package\n",
    "import requests #loading requests package\n",
    "import re #loading regex package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_human_kinase.csv\", index_col=0) #Read the kinase list csv file into a dataframe using pandas (pd)\n",
    "identifier = list(df.uniprot_number) #create an object that contains everything under the Uniprot Number\n",
    "geneName=list(df.gene_name) #create a object containing the gene names\n",
    "\n",
    "#Need to produce 2 URLs for each protein, that contains the unique kinase identifier number as well as the subcellular location from the database\n",
    "#As there are sometimes 2 pages of results, need to make sure there is a URL for page 1, and a URL for results on page 2\n",
    "url1= 'https://www.ebi.ac.uk/QuickGO/services/annotation/search?includeFields=goName&geneProductId=' #make an object containing the section of the quickGO URL before the kinase uniprot number\n",
    "url2= '&aspect=cellular_component&limit=100&page=1'#make an object containing the section of the quickGO URL after the kinase uniprot identifier (page 1)\n",
    "url3= '&aspect=cellular_component&limit=100&page=2'#make an object containing the section of the quickGO URL after the kinase uniprot identifier (page 2)\n",
    "\n",
    "quickGODataList=[]#Create empty list that will contain subcellular location information from quickGO from page 1 of results\n",
    "quickGODataList2=[]#Create empty list that will contain the subcellular location information from quickGO\n",
    "errorList=[]#create an empty list for any protein names that may not be found using quickGO\n",
    " \n",
    "for i in identifier: #for each kinase identifier\n",
    "    \n",
    "    try: #if no error is produced \n",
    "        url4=url1+i+url2 #Merge the 2 URL objects for page 1 of results, separated by the unique kimase idenifier name (i)\n",
    "        url5=url1+i+url3 #merge the 2 URLs for page 2 of results\n",
    "        quickGODataList.append(requests.get(url4).text) #append the information for each kinase to the list\n",
    "        quickGODataList2.append(requests.get(url5).text) #append the information for each kinase to the list\n",
    "    \n",
    "    except: #If an error is produced\n",
    "        errorList.append(i)#append the list to the output error list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make 2 empty lists, 1 for the list created from the results of searching the UniprotDataList using regex1\n",
    "#the other empty list is for the results of searching the results from regex1 using regex2\n",
    "kinaseInfoList=[]\n",
    "kinaseInfoList2=[]\n",
    "\n",
    "#Make a regex that will location the cellular component information from the quickGO results\n",
    "regex1=re.compile(r'\"goName\":\"[A-Za-z]*\\,*\\s*\\-*[a-z]*\\,*\\:*\\-*\\s*[A-Za-z]*\\<*\\-*\\s*[A-Za-z]*\\,*\\s*[A-Za-z]*\\-*\\,*\\s*[A-Za-z]*\"') #Created a regex that finds the subcellular location information\n",
    "\n",
    "#Search the quickGODataList using regex1, append results to KinaseInfoList\n",
    "for value in quickGODataList: #for each value (value is the data for one kinase)\n",
    "    kinaseInfoList.append(regex1.findall(value)) #append the results from the regex1 search to an empty list\n",
    "\n",
    "for value in quickGODataList2: #for each value (value is the data for one kinase)\n",
    "    kinaseInfoList2.append(regex1.findall(value))    \n",
    "\n",
    "#create two lists that will contain the strings after unnecessary characters are removed\n",
    "splitList=[]\n",
    "splitList2=[]\n",
    "\n",
    "#For each value in kinaseInfoList, remove extra characters that are not needed\n",
    "for i in kinaseInfoList:\n",
    "    i=str(i)\n",
    "    splitList.append(i.replace('\"','').replace('goName','').replace(\"[]\", \"\").replace(\"]\",\"\").replace(\"[\",\"\").replace(\"u':\",\"\").replace(\"'\",\"\"))\n",
    "\n",
    "#For each value in kinaseInfoList, remove extra characters that are not needed\n",
    "for j in kinaseInfoList2:\n",
    "    j=str(j)\n",
    "    splitList2.append(j.replace('\"','').replace('goName','').replace(\"[]\", \"\").replace(\"]\",\"\").replace(\"[\",\"\").replace(\"u':\",\"\").replace(\"'\",\"\"))\n",
    "\n",
    "#Make a dictionary containing the gene name, Uniprot Kinase Number identifier information and subcellular location information from each page of results\n",
    "kinaseDict= {'Gene Name':geneName, 'Uniprot Number':identifier,'Subcellular Location1':splitList, \"Subcellular Location2\":splitList2} #create a dictionary, with 'Protein', 'Position' and 'Residue'\n",
    "\n",
    "#Use pandas to make a dataframe from kinaseDict\n",
    "df=pd.DataFrame(kinaseDict) \n",
    "\n",
    "#Replace empty strings 'NaN' with 0\n",
    "df = df.replace(np.nan, 0)\n",
    "df['Subcellular Location']=df['Subcellular Location1'].astype(str)+','+df['Subcellular Location2'].astype(str)\n",
    "\n",
    "#Delete the columns for page 1 and 2\n",
    "del df['Subcellular Location1']\n",
    "del df['Subcellular Location2']\n",
    "\n",
    "#Need to Separate the list within cells of the dataframe so that each subcellular location is a separate row\n",
    "new_df=(df.set_index(['Gene Name','Uniprot Number']) #set index to uniprot number and gene name\n",
    "   .stack() #.stack() function reshapes the dataframe by converting the data into stacked form (pivots dataframe around index, which is protein, so data is rearranged vertically)\n",
    "   .str.split(',', expand=True) #split the values in the subcellular location column where there is a comma separating values \n",
    "   .stack()# #Use .stack() to once again pivot the dataframe around kinase identifier, so the data is stacked on top of eachother, removing the NULL values\n",
    "   .unstack(-2) #make the second to last (-2)index level the columns \n",
    "   .reset_index(-1, drop=True)#get rid of the last level using reset_index\n",
    "   .reset_index() #reset the index\n",
    ")\n",
    "\n",
    "#Remove any whitespace in the subcellular location column\n",
    "new_df['Subcellular Location']=new_df['Subcellular Location'].str.strip()\n",
    "\n",
    "#Tidy subcellular locations column by making all start of words capital letters\n",
    "new_df['Subcellular Location']=new_df['Subcellular Location'].str.title()\n",
    "\n",
    "#Drop rows where there are duplications in data(same subcellular location more than once for a kinase)\n",
    "new_df2=new_df.drop_duplicates()\n",
    "\n",
    "#Remove all rows where there are empty values in the Subcellular location column\n",
    "final_df = new_df2[new_df2['Subcellular Location'] != '']\n",
    "\n",
    "#Reindex dataframe\n",
    "final_df.reset_index()\n",
    "\n",
    "#Save the dataframe to a csv file\n",
    "final_df.to_csv('Subcellular_location.csv')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
